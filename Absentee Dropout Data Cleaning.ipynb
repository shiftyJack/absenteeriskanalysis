{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7570ca5-a4b2-409e-aeb6-f2aefaa5e469",
   "metadata": {},
   "source": [
    "I will use two files from 2017 in order to compare drop out rates to attendance. Chronicabsenteeis17 contains data on chronic absentees based on grade groupings by school. Dropouts17 contains the number of students who have dropped out by grade during that year. Adding those numbers for the corresponding grade grouping will allow me to compare chronic absenteeism to dropout rates. I could also look at overall poverty rate (school lunch data) for the year to see if the overall poverty rate for the school is correlated with the drop out rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beff01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DataFrame for Chronic Absentee data from 2017\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"chronicabsenteeism17.txt\", delimiter= '\\t', low_memory=False, on_bad_lines='skip', encoding = 'unicode_escape')\n",
    "df1 = df1[df1['AggregateLevel'] == \"S\"]\n",
    "df1 = df1[df1['ReportingCategory'] == \"GR912\"]\n",
    "\n",
    "#df1 = df1.drop(['AggregateLevel', 'CountyCode', 'DistrictCode', 'SchoolCode', 'CountyName', 'CharterYN'], axis = 1)\n",
    "df1 = df1.drop(['AggregateLevel', 'CountyName','DistrictName', 'SchoolName', 'CharterYN', 'ChronicAbsenteeismEligibleCumula', 'ChronicAbsenteeismCount'], axis = 1)\n",
    "\n",
    "#creating the school number from country, district and school code\n",
    "#getting rid of the blanks\n",
    "df1 = df1[df1['CountyCode'].notnull()]\n",
    "df1 = df1[df1['DistrictCode'].notnull()]\n",
    "df1 = df1[df1['SchoolCode'].notnull()]\n",
    "\n",
    "#ensuring the codes are the correct length\n",
    "df1['DistrictCode'] = df1['DistrictCode'].astype(str)\n",
    "#df1 = [df1['DistrictCode'].str.len() == 5]\n",
    "df1['DistrictCode'] = df1['DistrictCode'].str[:-2]+\"0\"\n",
    "\n",
    "df1['SchoolCode'] = df1['SchoolCode'].astype(str)\n",
    "#df1 = df1[df1['SchoolCode'].str.len() == 7]\n",
    "df1['SchoolCode'] = df1['SchoolCode'].str[:-2]\n",
    "\n",
    "#codelength = (df1['DistrictCode'].str.len() == 5) & (df1['SchoolCode'].str.len() == 7)\n",
    "#df1 = df1.loc[codelength]\n",
    "              \n",
    "df1['CDS_CODE'] = df1['CountyCode'].astype(str) + df1['DistrictCode'] + df1['SchoolCode']\n",
    "df1 = df1.drop(['CountyCode', 'DistrictCode', 'SchoolCode'], axis = 1)\n",
    "\n",
    "df1 = df1.rename(columns={\"AcademicYear\":\"Academic Year\", \"DistrictName\":\"District Name\", \"SchoolName\":\"School Name\", \"ReportingCategory\":\"Reporting Category\", \"ChronicAbsenteeismRate\":\"Absentee Rate\"})\n",
    "df1 = df1[df1['Absentee Rate'].notnull()]\n",
    "\n",
    "#reorder the columns with CDS CODE as Column 1\n",
    "#df1 = df1[['CDS_CODE',\n",
    "df1 = df1.sort_values('CDS_CODE')\n",
    "df1.to_csv('chronicabsenteeism17.csv', index = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b7ad0b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot subset columns with a tuple with more than one element. Use a list instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETOT\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDTOT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#df_dtot = df2.groupby(['CDS_CODE'])['DTOT'].sum().reset_index()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# TODO remove ETOT = 0\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df2[df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETOT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1947\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;66;03m# per GH 23566\u001b[39;00m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m-> 1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1950\u001b[0m     )\n\u001b[0;32m   1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot subset columns with a tuple with more than one element. Use a list instead."
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"filesdropouts17.txt\", delimiter= '\\t', low_memory=False, on_bad_lines='skip', encoding = 'unicode_escape')\n",
    "#df1 = df1[df1['AggregateLevel'] == \"S\"]\n",
    "df2 = df2.drop(['E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'EUS', 'D7', 'D8', 'DUS'], axis = 1)\n",
    "#df1 = df1.rename(columns={\"AcademicYear\":\"Academic Year\", \"DistrictName\":\"District Name\", \"SchoolName\":\"School Name\", \"ReportingCategory\":\"Reporting Category\", \"ChronicAbsenteeismEligibleCumula\":\"ChronicAbsenteeismEligibleCumulativeEnrollment\"})\n",
    "#df1 = df1[df1['ChronicAbsenteeismRate'].notnull()]\n",
    "df2 = df2.sort_values('CDS_CODE')\n",
    "df2['CDS_CODE'] = df2['CDS_CODE'].astype(str)\n",
    "df2 = df2.groupby(['CDS_CODE'])['ETOT','DTOT'].sum().reset_index()\n",
    "#df_dtot = df2.groupby(['CDS_CODE'])['DTOT'].sum().reset_index()\n",
    "\n",
    "# TODO remove ETOT = 0\n",
    "df2 = df2[df2['ETOT'] != 0]\n",
    "\n",
    "\n",
    "\n",
    "#merged_df = pd.merge(df1, df7[['School Name', 'Reporting Category', 'Graduate count']], on=['School Name', 'Reporting Category'], how='left')\n",
    "df2.to_csv('dropouts17.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d316a6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "do_df = pd.read_csv('dropouts17.csv')\n",
    "\n",
    "do_df['CDS_CODE'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64df2475-c2fd-44c5-b456-18cb77a9510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Dropout rate\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('dropouts17.csv','r') as csvinput:\n",
    "    with open('dropoutRates17.csv', 'w') as csvoutput:\n",
    "        writer = csv.writer(csvoutput, lineterminator='\\n')\n",
    "        reader = csv.reader(csvinput)\n",
    "\n",
    "        all = []\n",
    "        row = next(reader)\n",
    "        row.append('Dropout Rate')\n",
    "        all.append(row)\n",
    "\n",
    "        for row in reader:\n",
    "            row.append(float(row[2])/float(row[1]))\n",
    "            all.append(row)\n",
    "\n",
    "        writer.writerows(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44b6b3a-cfb1-40d4-ba47-9f20bb55b6df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df3 \u001b[38;5;241m=\u001b[39m df3[df3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#TODO make the rate non-decimal\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#df3 = df3[df3['Dropout Rate'].astype(float)*100]\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m      7\u001b[0m df3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDS_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#merged_df = pd.concat([df1, df3], sort = False)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "#Merge drop out rates with absenteeism\n",
    "df3 = pd.read_csv('dropoutRates17.csv')\n",
    "df3 = df3[df3['Dropout Rate'] <= 1]\n",
    "#TODO make the rate non-decimal\n",
    "#df3 = df3[df3['Dropout Rate'].astype(float)*100]\n",
    "df1['CDS_CODE'] = df1['CDS_CODE'].astype(str)\n",
    "df3['CDS_CODE'] = df3['CDS_CODE'].astype(str)\n",
    "\n",
    "#merged_df = pd.concat([df1, df3], sort = False)\n",
    "merged_df = pd.merge(df1, df3, on = 'CDS_CODE')\n",
    "merged_df = merged_df.drop(['Academic Year', 'Reporting Category', 'ETOT', 'DTOT', 'CDS_CODE'], axis = 1)\n",
    "merged_df = merged_df[['Absentee Rate', 'Dropout Rate']]\n",
    "merged_df = merged_df.sort_values(by=['Absentee Rate'])\n",
    "merged_df.to_csv('merged17.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "feba30de-9940-47a8-9e3d-5744721178a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m haversine_distances\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpatches\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m absentees \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbsentee Rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m      8\u001b[0m dropouts \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout Rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m), dpi \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "absentees = merged_df['Absentee Rate'].to_list()\n",
    "dropouts = merged_df['Dropout Rate'].to_list()\n",
    "\n",
    "plt.figure(figsize=(8,6), dpi = 500)\n",
    "plt.plot(absentees, dropouts, 'ko')\n",
    "plt.xlabel('School Absentee Rates')\n",
    "plt.ylabel('School Dropout Rates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26c79d89-2dbd-491e-8810-f76d5ca2948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_dropoutrisk(absenteerate, dropoutrate):\n",
    "    \n",
    "    '''\n",
    "    Performs linear regression on the given absentee rates and dropout rates\n",
    "    \n",
    "    Args:\n",
    "        absentee_rates: a list of absentee rates for various schools\n",
    "        dropout_rates: a list of dropout rates for the same schools\n",
    "    Returns:\n",
    "        a tuple of the slope and the intercept of the linear regression line\n",
    "    '''\n",
    "    \n",
    "    absentee_rate = np.array(absentees)\n",
    "    dropout_rate = np.array(dropouts)\n",
    "    \n",
    "    #calculate mean values\n",
    "    mean_absentee_rate = np.mean(absentee_rate)\n",
    "    mean_dropout_rate = np.mean(dropout_rate)\n",
    "    \n",
    "    #numerator and demoninator for slope\n",
    "    numerator = np.sum((absentee_rate - mean_absentee_rate) * (dropout_rate - mean_dropout_rate))\n",
    "    denominator = np.sum((absentee_rate - mean_absentee_rate) **2)\n",
    "    \n",
    "    #slope\n",
    "    m = numerator/denominator\n",
    "    b = mean_dropout_rate - m * mean_absentee_rate\n",
    "    \n",
    "    return m,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0ccc5ae-4acb-4637-92b4-502d40d065a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'absentees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Do linear regression\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m slope, intercept \u001b[38;5;241m=\u001b[39m linear_regression_dropoutrisk(absentees, dropouts)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#print slop and intercept for these data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSlope (m):\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(slope,\u001b[38;5;241m6\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercent School Dropouts/Percent School Absenteeism\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'absentees' is not defined"
     ]
    }
   ],
   "source": [
    "#Do linear regression\n",
    "slope, intercept = linear_regression_dropoutrisk(absentees, dropouts)\n",
    "\n",
    "#print slop and intercept for these data\n",
    "print(\"Slope (m):\", round(slope,6), 'Percent School Dropouts/Percent School Absenteeism')\n",
    "print(\"Intercept (b):\", round(intercept,6))\n",
    "\n",
    "#arrays for the line\n",
    "regression_x = np.array([np.min(absentees), np.max(absentees)])\n",
    "regression_y = slope * regression_x + intercept\n",
    "\n",
    "plt.figure(figsize=(8,6), dpi = 500)\n",
    "plt.plot(absentees, dropouts, 'ko')\n",
    "plt.plot(regression_x, regression_y,'r-')\n",
    "plt.xlabel('School Absentee Rates')\n",
    "plt.ylabel('School Dropout Rates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e5e877-7d0e-48f5-91bb-f76bc10b8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_csv(\"filesdropouts17.txt\", delimiter= '\\t', low_memory=False, on_bad_lines='skip', encoding = 'unicode_escape')\n",
    "df2.to_csv('dropouts.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00361708-fdbf-4d11-bd1c-72e0c3cb23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv(\"chronicabsenteeism17.txt\", delimiter= '\\t', low_memory=False, on_bad_lines='skip', encoding = 'unicode_escape')\n",
    "\n",
    "dfTest.to_csv('absentTest.csv', index = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01030bce-d76d-4684-aa6f-d2b330592aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPov = pd.read_excel(\"frpm1617.xls\", sheet_name= \"FRPM School-Level Data \")\n",
    "dfPov = dfPov.drop(['Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27'], axis = 1)\n",
    "\n",
    "dfPov = dfPov.rename(columns={\"FRPM School-Level Data\":\"Academic Year\", \"Unnamed: 1\":\"County Code\", \"Unnamed: 2\":\"District Code\", \"Unnamed: 3\":\"School Code\", \"Unnamed: 21\":\"School Pov Rate\"})\n",
    "\n",
    "dfPov['CDS_CODE'] = dfPov['County Code'].astype(str) + dfPov['District Code'] + dfPov['School Code']\n",
    "dfPov = dfPov.drop(['County Code', 'District Code', 'School Code'], axis = 1)\n",
    "\n",
    "dfPov.to_csv('poverty17.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72905140-fffd-416a-b090-99a58f6e6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Poverty with drop out rates and absenteeism\n",
    "\n",
    "dfPov['CDS_CODE'] = dfPov['CDS_CODE'].astype(str)\n",
    "\n",
    "#merged_df = pd.concat([df1, df3], sort = False)\n",
    "new_merged_df = pd.read_csv(\"merged17.csv\")\n",
    "merged_df = merged_df.drop(['Academic Year', 'Reporting Category', 'ETOT', 'DTOT', 'CDS_CODE'], axis = 1)\n",
    "#merged_df = merged_df[['Absentee Rate', 'Dropout Rate']]\n",
    "#merged_df = merged_df.sort_values(by=['Absentee Rate'])\n",
    "new_merged_df.to_csv('newmerged17.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ffebd-99ac-440c-bd79-9bff9255ccd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
